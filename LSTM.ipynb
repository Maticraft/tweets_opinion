{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, IterableDataset, DataLoader\r\n",
        "from itertools import cycle, islice\r\n",
        "from string import punctuation\r\n",
        "import random\r\n",
        "import linecache\r\n",
        "import mmap\r\n",
        "import numpy as np\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "\r\n",
        "from lstm import LSTM\r\n",
        "from utils import encode, load_vocab"
      ],
      "outputs": [],
      "metadata": {
        "id": "u-9uscQh-2vO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# Data set definition\r\n",
        "\r\n",
        "class MyIterableDataset(IterableDataset):\r\n",
        "    \"\"\"\r\n",
        "    inputs:\r\n",
        "      filepath - tweets dataset filepath\r\n",
        "      vocab - vocabulary\r\n",
        "      wordsNb - number of words used in one sequence\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, filepath, vocab, wordsNb, shuffled = True):\r\n",
        "      self.filepath = filepath\r\n",
        "      self.examplesNum = self.linesNb(self.filepath)\r\n",
        "      self.order = np.random.permutation(np.arange(self.examplesNum))\r\n",
        "      self.vocab = vocab\r\n",
        "      self.shuffled = shuffled\r\n",
        "      self.ps = PorterStemmer()\r\n",
        "      self.length = wordsNb\r\n",
        "      \r\n",
        "\r\n",
        "    def linesNb(self, filepath):\r\n",
        "      \r\n",
        "      f = open(filepath, \"r+\")\r\n",
        "      buf = mmap.mmap(f.fileno(), 0)\r\n",
        "      lines = 0\r\n",
        "      readline = buf.readline\r\n",
        "\r\n",
        "      while readline():\r\n",
        "        lines += 1\r\n",
        "\r\n",
        "      return lines\r\n",
        "\r\n",
        "\r\n",
        "    def __iter__(self):\r\n",
        "      if self.shuffled:\r\n",
        "        return self.get_shuffled_Stream(self.filepath, self.order, self.vocab, self.ps, self.length)\r\n",
        "      else:\r\n",
        "        return self.get_stream(self.filepath, self.vocab, self.ps, self.length)  \r\n",
        "\r\n",
        "    \r\n",
        "    def get_stream(self, filepath, vocab, ps, length):\r\n",
        "      return self.parse_file(filepath, vocab, ps, length)\r\n",
        "\r\n",
        "\r\n",
        "    def get_shuffled_Stream(self, filepath, order, vocab, ps, length):\r\n",
        "      return self.parse_file_ord(filepath, order, vocab, ps, length)\r\n",
        "\r\n",
        "\r\n",
        "    # parsing the file with examples order inherited from the orginal file\r\n",
        "    def parse_file(self, filepath, vocab, ps, length):\r\n",
        "      \r\n",
        "      with open(filepath, 'r', encoding=\"latin-1\") as file_obj:\r\n",
        "        for line in file_obj:\r\n",
        "          try:\r\n",
        "            yield self.process_line(line, vocab, ps, length)\r\n",
        "          except IndexError:\r\n",
        "            pass\r\n",
        "\r\n",
        "\r\n",
        "    # parsing the file with new examples order\r\n",
        "    def parse_file_ord(self, filepath, order, vocab, ps, length):\r\n",
        "      \r\n",
        "      for indx in order:\r\n",
        "        line = linecache.getline(filepath, indx)\r\n",
        "        try:\r\n",
        "          yield self.process_line(line, vocab, ps, length)\r\n",
        "        except IndexError:\r\n",
        "          pass\r\n",
        "\r\n",
        "    \r\n",
        "    # processing the data into the pytorch tensors\r\n",
        "    def process_line(self, line, vocab, ps, length):\r\n",
        "      token = (line.strip(\"\\n\").split('\",\"')[0].translate(str.maketrans(\"\", \"\", punctuation)), line.strip(\"\\n\").split('\",\"')[5].translate(str.maketrans(\"\", \"\", punctuation)).lower())\r\n",
        "      tensor = encode(token[1], vocab, ps, length)\r\n",
        "      label = float(token[0])\r\n",
        "      if label == 4:\r\n",
        "        label = 1\r\n",
        "      label = torch.unsqueeze(torch.tensor(label), dim = 0)\r\n",
        "      return (label, tensor)"
      ],
      "outputs": [],
      "metadata": {
        "id": "gJn6diA4_Jxz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Initializing the parameters of the network, loading the vocabulary and constructing the data set\r\n",
        "\r\n",
        "batch_size = 256\r\n",
        "wordsNb = 30\r\n",
        "hidden_size = 128\r\n",
        "classes = 1\r\n",
        "num_layers = 1\r\n",
        "learning_rate = 0.0001\r\n",
        "\r\n",
        "vocabulary = load_vocab(\"./data/vocab.txt\")\r\n",
        "input_size = len(vocabulary) + 2\r\n",
        "\r\n",
        "shuffled = MyIterableDataset('./data/tweets.csv', vocabulary, wordsNb, shuffled = True)\r\n",
        "examplesNum = shuffled.examplesNum\r\n",
        "testNum = round(0.01*examplesNum)\r\n",
        "trainNum = examplesNum - testNum\r\n",
        "trainBatches = round(trainNum/batch_size)\r\n",
        "testBatches = round(testNum/batch_size) - 2"
      ],
      "outputs": [],
      "metadata": {
        "id": "K7MuZD71_WJh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaf1Msne_f8F",
        "outputId": "933bdb25-1499-43ed-87ab-3ab71553bb1f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Initializing the model and defining the loss\r\n",
        "\r\n",
        "lstm = LSTM(input_size, hidden_size, num_layers, wordsNb, classes, batch_size)\r\n",
        "lstm.to(device)\r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr = learning_rate)\r\n",
        "loader = DataLoader(shuffled, batch_size = batch_size)"
      ],
      "outputs": [],
      "metadata": {
        "id": "bvqePp4ZAGWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Training\r\n",
        "\r\n",
        "for epoch in range(5):\r\n",
        "    lstm.train()\r\n",
        "    batch = 0\r\n",
        "    epoch_loss = 0\r\n",
        "    ave_loss = 0\r\n",
        "    acc = 0\r\n",
        "\r\n",
        "    for y_batch, x_batch in loader:\r\n",
        "\r\n",
        "        y_batch1 = y_batch.to(device)\r\n",
        "        x_batch1 = x_batch.to(device)\r\n",
        "\r\n",
        "        batch += 1\r\n",
        "        lstm.zero_grad()        \r\n",
        "        output = lstm(x_batch1) \r\n",
        "        loss = criterion(output, y_batch1)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        for i in range(len(y_batch)):\r\n",
        "          \r\n",
        "          \r\n",
        "          if round(output[i].item()) == (y_batch1[i].item()):\r\n",
        "            acc += 1\r\n",
        "\r\n",
        "        ave_loss += loss.item()\r\n",
        "        epoch_loss += loss.item() \r\n",
        "\r\n",
        "        if batch % 100 == 0:\r\n",
        "            print(\"Epoch\", epoch + 1, \"Batch:\", batch, \"TR:\", ave_loss/100, \"Acc:\", acc/(100*batch_size))\r\n",
        "            ave_loss = 0\r\n",
        "            acc = 0\r\n",
        "\r\n",
        "        if batch >= trainBatches:\r\n",
        "          break\r\n",
        "\r\n",
        "    print(\"Epoch: \", epoch + 1, \"loss:\", epoch_loss/batch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch: 100 TR: 0.6935465967655182 Acc: 0.4991015625\n",
            "Epoch 1 Batch: 200 TR: 0.6927824187278747 Acc: 0.5103515625\n",
            "Epoch 1 Batch: 300 TR: 0.687918428182602 Acc: 0.5533203125\n",
            "Epoch 1 Batch: 400 TR: 0.6148731642961502 Acc: 0.6703515625\n",
            "Epoch 1 Batch: 500 TR: 0.5393537142872811 Acc: 0.73328125\n",
            "Epoch 1 Batch: 600 TR: 0.517388376891613 Acc: 0.7511328125\n",
            "Epoch 1 Batch: 700 TR: 0.5072230377793312 Acc: 0.756171875\n",
            "Epoch 1 Batch: 800 TR: 0.49535665482282637 Acc: 0.766015625\n",
            "Epoch 1 Batch: 900 TR: 0.49432676047086715 Acc: 0.766484375\n",
            "Epoch 1 Batch: 1000 TR: 0.4845884299278259 Acc: 0.773828125\n",
            "Epoch 1 Batch: 1100 TR: 0.47900554895401 Acc: 0.7770703125\n",
            "Epoch 1 Batch: 1200 TR: 0.47515646934509276 Acc: 0.7786328125\n",
            "Epoch 1 Batch: 1300 TR: 0.4719967800378799 Acc: 0.781796875\n",
            "Epoch 1 Batch: 1400 TR: 0.4712123861908913 Acc: 0.779921875\n",
            "Epoch 1 Batch: 1500 TR: 0.4695120421051979 Acc: 0.7821484375\n",
            "Epoch 1 Batch: 1600 TR: 0.46804407984018326 Acc: 0.7828515625\n",
            "Epoch 1 Batch: 1700 TR: 0.46306814908981325 Acc: 0.786328125\n",
            "Epoch 1 Batch: 1800 TR: 0.4689358514547348 Acc: 0.7779296875\n",
            "Epoch 1 Batch: 1900 TR: 0.45943875521421434 Acc: 0.7860546875\n",
            "Epoch 1 Batch: 2000 TR: 0.454675028026104 Acc: 0.786484375\n",
            "Epoch 1 Batch: 2100 TR: 0.4586179792881012 Acc: 0.7841015625\n",
            "Epoch 1 Batch: 2200 TR: 0.45461827009916306 Acc: 0.7890625\n",
            "Epoch 1 Batch: 2300 TR: 0.45892753690481186 Acc: 0.7890625\n",
            "Epoch 1 Batch: 2400 TR: 0.4484108871221542 Acc: 0.792265625\n",
            "Epoch 1 Batch: 2500 TR: 0.45025959581136704 Acc: 0.7907421875\n",
            "Epoch 1 Batch: 2600 TR: 0.4475059139728546 Acc: 0.792890625\n",
            "Epoch 1 Batch: 2700 TR: 0.4440755015611649 Acc: 0.7960546875\n",
            "Epoch 1 Batch: 2800 TR: 0.45339875280857084 Acc: 0.79203125\n",
            "Epoch 1 Batch: 2900 TR: 0.44560992091894147 Acc: 0.79578125\n",
            "Epoch 1 Batch: 3000 TR: 0.4518119767308235 Acc: 0.789375\n",
            "Epoch 1 Batch: 3100 TR: 0.4500539258122444 Acc: 0.78921875\n",
            "Epoch 1 Batch: 3200 TR: 0.45219830602407457 Acc: 0.78671875\n",
            "Epoch 1 Batch: 3300 TR: 0.4469298529624939 Acc: 0.793046875\n",
            "Epoch 1 Batch: 3400 TR: 0.44626770317554476 Acc: 0.7930859375\n",
            "Epoch 1 Batch: 3500 TR: 0.4466509810090065 Acc: 0.7957421875\n",
            "Epoch 1 Batch: 3600 TR: 0.44503758460283277 Acc: 0.7930078125\n",
            "Epoch 1 Batch: 3700 TR: 0.45407117903232574 Acc: 0.7877734375\n",
            "Epoch 1 Batch: 3800 TR: 0.4467767786979675 Acc: 0.792890625\n",
            "Epoch 1 Batch: 3900 TR: 0.4492981106042862 Acc: 0.7911328125\n",
            "Epoch 1 Batch: 4000 TR: 0.44590664327144625 Acc: 0.7925\n",
            "Epoch 1 Batch: 4100 TR: 0.44555261701345444 Acc: 0.7951171875\n",
            "Epoch 1 Batch: 4200 TR: 0.4412972074747086 Acc: 0.7982421875\n",
            "Epoch 1 Batch: 4300 TR: 0.446384496986866 Acc: 0.7921875\n",
            "Epoch 1 Batch: 4400 TR: 0.4406294947862625 Acc: 0.795078125\n",
            "Epoch 1 Batch: 4500 TR: 0.44496543109416964 Acc: 0.7942578125\n",
            "Epoch 1 Batch: 4600 TR: 0.43959916293621065 Acc: 0.79671875\n",
            "Epoch 1 Batch: 4700 TR: 0.441481793820858 Acc: 0.79671875\n",
            "Epoch 1 Batch: 4800 TR: 0.43811045855283737 Acc: 0.7984375\n",
            "Epoch 1 Batch: 4900 TR: 0.44068740665912626 Acc: 0.79734375\n",
            "Epoch 1 Batch: 5000 TR: 0.4367173421382904 Acc: 0.7998046875\n",
            "Epoch 1 Batch: 5100 TR: 0.43744998961687087 Acc: 0.798984375\n",
            "Epoch 1 Batch: 5200 TR: 0.4416594463586807 Acc: 0.797421875\n",
            "Epoch 1 Batch: 5300 TR: 0.4422611036896706 Acc: 0.795390625\n",
            "Epoch 1 Batch: 5400 TR: 0.44051905781030654 Acc: 0.799453125\n",
            "Epoch 1 Batch: 5500 TR: 0.4356721246242523 Acc: 0.7984375\n",
            "Epoch 1 Batch: 5600 TR: 0.4340709179639816 Acc: 0.80109375\n",
            "Epoch 1 Batch: 5700 TR: 0.4364156353473663 Acc: 0.800078125\n",
            "Epoch 1 Batch: 5800 TR: 0.44488470554351806 Acc: 0.793671875\n",
            "Epoch 1 Batch: 5900 TR: 0.4415477693080902 Acc: 0.7946875\n",
            "Epoch 1 Batch: 6000 TR: 0.4388356474041939 Acc: 0.7962890625\n",
            "Epoch 1 Batch: 6100 TR: 0.4429321900010109 Acc: 0.79234375\n",
            "Epoch:  1 loss: 0.46933758555975896\n",
            "Epoch 2 Batch: 100 TR: 0.43332299917936323 Acc: 0.80125\n",
            "Epoch 2 Batch: 200 TR: 0.43959410578012464 Acc: 0.7961328125\n",
            "Epoch 2 Batch: 300 TR: 0.43630901038646697 Acc: 0.798046875\n",
            "Epoch 2 Batch: 400 TR: 0.428532737493515 Acc: 0.8033203125\n",
            "Epoch 2 Batch: 500 TR: 0.419414381980896 Acc: 0.8077734375\n",
            "Epoch 2 Batch: 600 TR: 0.4258718603849411 Acc: 0.805703125\n",
            "Epoch 2 Batch: 700 TR: 0.4290059933066368 Acc: 0.8020703125\n",
            "Epoch 2 Batch: 800 TR: 0.42856042832136154 Acc: 0.80484375\n",
            "Epoch 2 Batch: 900 TR: 0.43215357542037963 Acc: 0.8015625\n",
            "Epoch 2 Batch: 1000 TR: 0.42474523216485977 Acc: 0.804140625\n",
            "Epoch 2 Batch: 1100 TR: 0.42766610622406004 Acc: 0.8051953125\n",
            "Epoch 2 Batch: 1200 TR: 0.42656505465507505 Acc: 0.804375\n",
            "Epoch 2 Batch: 1300 TR: 0.4225157454609871 Acc: 0.807734375\n",
            "Epoch 2 Batch: 1400 TR: 0.4281392151117325 Acc: 0.8002734375\n",
            "Epoch 2 Batch: 1500 TR: 0.42523982673883437 Acc: 0.80484375\n",
            "Epoch 2 Batch: 1600 TR: 0.4305519610643387 Acc: 0.80109375\n",
            "Epoch 2 Batch: 1700 TR: 0.42423086762428286 Acc: 0.8051953125\n",
            "Epoch 2 Batch: 1800 TR: 0.4338650435209274 Acc: 0.7989453125\n",
            "Epoch 2 Batch: 1900 TR: 0.425363572537899 Acc: 0.806640625\n",
            "Epoch 2 Batch: 2000 TR: 0.42172307580709456 Acc: 0.8064453125\n",
            "Epoch 2 Batch: 2100 TR: 0.4276380524039268 Acc: 0.8039453125\n",
            "Epoch 2 Batch: 2200 TR: 0.42454616755247115 Acc: 0.804921875\n",
            "Epoch 2 Batch: 2300 TR: 0.4292449563741684 Acc: 0.8048828125\n",
            "Epoch 2 Batch: 2400 TR: 0.4208652240037918 Acc: 0.8072265625\n",
            "Epoch 2 Batch: 2500 TR: 0.4227201360464096 Acc: 0.8046484375\n",
            "Epoch 2 Batch: 2600 TR: 0.42073054999113085 Acc: 0.807578125\n",
            "Epoch 2 Batch: 2700 TR: 0.4171088254451752 Acc: 0.8090234375\n",
            "Epoch 2 Batch: 2800 TR: 0.4278908595442772 Acc: 0.8036328125\n",
            "Epoch 2 Batch: 2900 TR: 0.42293187230825424 Acc: 0.80921875\n",
            "Epoch 2 Batch: 3000 TR: 0.42815664649009705 Acc: 0.80359375\n",
            "Epoch 2 Batch: 3100 TR: 0.4265439558029175 Acc: 0.8015234375\n",
            "Epoch 2 Batch: 3200 TR: 0.42893738359212874 Acc: 0.7994921875\n",
            "Epoch 2 Batch: 3300 TR: 0.4240207374095917 Acc: 0.806015625\n",
            "Epoch 2 Batch: 3400 TR: 0.42365964740514755 Acc: 0.80703125\n",
            "Epoch 2 Batch: 3500 TR: 0.425780348777771 Acc: 0.8046484375\n",
            "Epoch 2 Batch: 3600 TR: 0.4228025007247925 Acc: 0.8038671875\n",
            "Epoch 2 Batch: 3700 TR: 0.43178971618413925 Acc: 0.8005078125\n",
            "Epoch 2 Batch: 3800 TR: 0.4252736407518387 Acc: 0.804453125\n",
            "Epoch 2 Batch: 3900 TR: 0.427960476577282 Acc: 0.8062109375\n",
            "Epoch 2 Batch: 4000 TR: 0.42478423833847045 Acc: 0.804921875\n",
            "Epoch 2 Batch: 4100 TR: 0.42488524943590167 Acc: 0.8058203125\n",
            "Epoch 2 Batch: 4200 TR: 0.4212071657180786 Acc: 0.8078515625\n",
            "Epoch 2 Batch: 4300 TR: 0.42677385717630384 Acc: 0.8038671875\n",
            "Epoch 2 Batch: 4400 TR: 0.420933304131031 Acc: 0.8071484375\n",
            "Epoch 2 Batch: 4500 TR: 0.42439950674772264 Acc: 0.805078125\n",
            "Epoch 2 Batch: 4600 TR: 0.42061398208141326 Acc: 0.806640625\n",
            "Epoch 2 Batch: 4700 TR: 0.4213895884156227 Acc: 0.8083203125\n",
            "Epoch 2 Batch: 4800 TR: 0.4187226003408432 Acc: 0.8104296875\n",
            "Epoch 2 Batch: 4900 TR: 0.42126981288194654 Acc: 0.8093359375\n",
            "Epoch 2 Batch: 5000 TR: 0.4168818897008896 Acc: 0.8108203125\n",
            "Epoch 2 Batch: 5100 TR: 0.41924661487340925 Acc: 0.8105859375\n",
            "Epoch 2 Batch: 5200 TR: 0.42335676282644275 Acc: 0.805703125\n",
            "Epoch 2 Batch: 5300 TR: 0.4232809919118881 Acc: 0.80390625\n",
            "Epoch 2 Batch: 5400 TR: 0.42349212765693667 Acc: 0.806640625\n",
            "Epoch 2 Batch: 5500 TR: 0.4172142222523689 Acc: 0.80703125\n",
            "Epoch 2 Batch: 5600 TR: 0.41653929084539415 Acc: 0.809921875\n",
            "Epoch 2 Batch: 5700 TR: 0.41881577521562574 Acc: 0.8085546875\n",
            "Epoch 2 Batch: 5800 TR: 0.4277926397323608 Acc: 0.799921875\n",
            "Epoch 2 Batch: 5900 TR: 0.421939238011837 Acc: 0.80421875\n",
            "Epoch 2 Batch: 6000 TR: 0.4200556838512421 Acc: 0.8057421875\n",
            "Epoch 2 Batch: 6100 TR: 0.4249564316868782 Acc: 0.800546875\n",
            "Epoch:  2 loss: 0.42488458956836805\n",
            "Epoch 3 Batch: 100 TR: 0.417610385119915 Acc: 0.810234375\n",
            "Epoch 3 Batch: 200 TR: 0.4224711218476295 Acc: 0.804765625\n",
            "Epoch 3 Batch: 300 TR: 0.4216544869542122 Acc: 0.805390625\n",
            "Epoch 3 Batch: 400 TR: 0.4137831926345825 Acc: 0.810703125\n",
            "Epoch 3 Batch: 500 TR: 0.40463048428297044 Acc: 0.8151953125\n",
            "Epoch 3 Batch: 600 TR: 0.4121973264217377 Acc: 0.8102734375\n",
            "Epoch 3 Batch: 700 TR: 0.4150205847620964 Acc: 0.8091796875\n",
            "Epoch 3 Batch: 800 TR: 0.4145195844769478 Acc: 0.809140625\n",
            "Epoch 3 Batch: 900 TR: 0.41812487185001374 Acc: 0.8080078125\n",
            "Epoch 3 Batch: 1000 TR: 0.4092439043521881 Acc: 0.813046875\n",
            "Epoch 3 Batch: 1100 TR: 0.4153412050008774 Acc: 0.8111328125\n",
            "Epoch 3 Batch: 1200 TR: 0.41146004050970075 Acc: 0.812109375\n",
            "Epoch 3 Batch: 1300 TR: 0.4077547663450241 Acc: 0.81421875\n",
            "Epoch 3 Batch: 1400 TR: 0.4148237031698227 Acc: 0.809453125\n",
            "Epoch 3 Batch: 1500 TR: 0.41051825642585754 Acc: 0.811640625\n",
            "Epoch 3 Batch: 1600 TR: 0.41767448991537093 Acc: 0.806875\n",
            "Epoch 3 Batch: 1700 TR: 0.4093176054954529 Acc: 0.814609375\n",
            "Epoch 3 Batch: 1800 TR: 0.4203564900159836 Acc: 0.805546875\n",
            "Epoch 3 Batch: 1900 TR: 0.4123223587870598 Acc: 0.8133203125\n",
            "Epoch 3 Batch: 2000 TR: 0.4088150146603584 Acc: 0.812890625\n",
            "Epoch 3 Batch: 2100 TR: 0.4121453872323036 Acc: 0.8107421875\n",
            "Epoch 3 Batch: 2200 TR: 0.4110052093863487 Acc: 0.811640625\n",
            "Epoch 3 Batch: 2300 TR: 0.41375353127717973 Acc: 0.8107421875\n",
            "Epoch 3 Batch: 2400 TR: 0.4068341264128685 Acc: 0.814453125\n",
            "Epoch 3 Batch: 2500 TR: 0.40885075569152834 Acc: 0.8112890625\n",
            "Epoch 3 Batch: 2600 TR: 0.40600959688425065 Acc: 0.8139453125\n",
            "Epoch 3 Batch: 2700 TR: 0.40274722754955294 Acc: 0.817109375\n",
            "Epoch 3 Batch: 2800 TR: 0.4135227638483048 Acc: 0.809765625\n",
            "Epoch 3 Batch: 2900 TR: 0.4096278116106987 Acc: 0.8145703125\n",
            "Epoch 3 Batch: 3000 TR: 0.4155270129442215 Acc: 0.80734375\n",
            "Epoch 3 Batch: 3100 TR: 0.41185413151979444 Acc: 0.80953125\n",
            "Epoch 3 Batch: 3200 TR: 0.41537117570638654 Acc: 0.8069921875\n",
            "Epoch 3 Batch: 3300 TR: 0.4094515800476074 Acc: 0.8117578125\n",
            "Epoch 3 Batch: 3400 TR: 0.41063169986009596 Acc: 0.812578125\n",
            "Epoch 3 Batch: 3500 TR: 0.4134096518158913 Acc: 0.8109765625\n",
            "Epoch 3 Batch: 3600 TR: 0.4106333255767822 Acc: 0.80890625\n",
            "Epoch 3 Batch: 3700 TR: 0.4170553207397461 Acc: 0.8096875\n",
            "Epoch 3 Batch: 3800 TR: 0.41147391736507416 Acc: 0.8101171875\n",
            "Epoch 3 Batch: 3900 TR: 0.4131970217823982 Acc: 0.8131640625\n",
            "Epoch 3 Batch: 4000 TR: 0.4123552694916725 Acc: 0.8117578125\n",
            "Epoch 3 Batch: 4100 TR: 0.4108698722720146 Acc: 0.8131640625\n",
            "Epoch 3 Batch: 4200 TR: 0.407528392970562 Acc: 0.815\n",
            "Epoch 3 Batch: 4300 TR: 0.4134726068377495 Acc: 0.80953125\n",
            "Epoch 3 Batch: 4400 TR: 0.40742446839809415 Acc: 0.8140625\n",
            "Epoch 3 Batch: 4500 TR: 0.4101458114385605 Acc: 0.811875\n",
            "Epoch 3 Batch: 4600 TR: 0.4074435552954674 Acc: 0.8134765625\n",
            "Epoch 3 Batch: 4700 TR: 0.40854527443647387 Acc: 0.8147265625\n",
            "Epoch 3 Batch: 4800 TR: 0.40561855137348174 Acc: 0.8170703125\n",
            "Epoch 3 Batch: 4900 TR: 0.40877597153186795 Acc: 0.8142578125\n",
            "Epoch 3 Batch: 5000 TR: 0.40449313193559644 Acc: 0.817265625\n",
            "Epoch 3 Batch: 5100 TR: 0.40825129151344297 Acc: 0.8146484375\n",
            "Epoch 3 Batch: 5200 TR: 0.41165858060121535 Acc: 0.8130078125\n",
            "Epoch 3 Batch: 5300 TR: 0.41038919627666476 Acc: 0.8105859375\n",
            "Epoch 3 Batch: 5400 TR: 0.41165833950042724 Acc: 0.8115625\n",
            "Epoch 3 Batch: 5500 TR: 0.40455434381961825 Acc: 0.8137109375\n",
            "Epoch 3 Batch: 5600 TR: 0.4054153835773468 Acc: 0.8144921875\n",
            "Epoch 3 Batch: 5700 TR: 0.40652567595243455 Acc: 0.814609375\n",
            "Epoch 3 Batch: 5800 TR: 0.4144358116388321 Acc: 0.8087109375\n",
            "Epoch 3 Batch: 5900 TR: 0.40793877869844436 Acc: 0.811328125\n",
            "Epoch 3 Batch: 6000 TR: 0.40850675851106644 Acc: 0.8133203125\n",
            "Epoch 3 Batch: 6100 TR: 0.4133452412486076 Acc: 0.80765625\n",
            "Epoch:  3 loss: 0.4112940507458731\n",
            "Epoch 4 Batch: 100 TR: 0.4062640804052353 Acc: 0.8150390625\n",
            "Epoch 4 Batch: 200 TR: 0.41044343829154967 Acc: 0.80953125\n",
            "Epoch 4 Batch: 300 TR: 0.4106997403502464 Acc: 0.8100390625\n",
            "Epoch 4 Batch: 400 TR: 0.40259800434112547 Acc: 0.815859375\n",
            "Epoch 4 Batch: 500 TR: 0.3946865376830101 Acc: 0.8194140625\n",
            "Epoch 4 Batch: 600 TR: 0.4031326100230217 Acc: 0.8151171875\n",
            "Epoch 4 Batch: 700 TR: 0.40488856166601184 Acc: 0.81515625\n",
            "Epoch 4 Batch: 800 TR: 0.40435996145009995 Acc: 0.8159765625\n",
            "Epoch 4 Batch: 900 TR: 0.40823033064603803 Acc: 0.8133984375\n",
            "Epoch 4 Batch: 1000 TR: 0.3986078736186027 Acc: 0.818828125\n",
            "Epoch 4 Batch: 1100 TR: 0.40656597793102267 Acc: 0.8141015625\n",
            "Epoch 4 Batch: 1200 TR: 0.40135076612234116 Acc: 0.8168359375\n",
            "Epoch 4 Batch: 1300 TR: 0.3981476026773453 Acc: 0.820390625\n",
            "Epoch 4 Batch: 1400 TR: 0.40530345171689985 Acc: 0.81515625\n",
            "Epoch 4 Batch: 1500 TR: 0.4007742655277252 Acc: 0.816796875\n",
            "Epoch 4 Batch: 1600 TR: 0.4064522761106491 Acc: 0.8118359375\n",
            "Epoch 4 Batch: 1700 TR: 0.3996486127376556 Acc: 0.8171875\n",
            "Epoch 4 Batch: 1800 TR: 0.4106538110971451 Acc: 0.811015625\n",
            "Epoch 4 Batch: 1900 TR: 0.4030968505144119 Acc: 0.8173046875\n",
            "Epoch 4 Batch: 2000 TR: 0.39996407061815265 Acc: 0.81734375\n",
            "Epoch 4 Batch: 2100 TR: 0.4012788489460945 Acc: 0.815234375\n",
            "Epoch 4 Batch: 2200 TR: 0.40105209857225416 Acc: 0.81734375\n",
            "Epoch 4 Batch: 2300 TR: 0.4034605145454407 Acc: 0.8171484375\n",
            "Epoch 4 Batch: 2400 TR: 0.39765307754278184 Acc: 0.81921875\n",
            "Epoch 4 Batch: 2500 TR: 0.3990919995307922 Acc: 0.81859375\n",
            "Epoch 4 Batch: 2600 TR: 0.3961939153075218 Acc: 0.8196484375\n",
            "Epoch 4 Batch: 2700 TR: 0.39306516617536547 Acc: 0.82234375\n",
            "Epoch 4 Batch: 2800 TR: 0.40399096071720125 Acc: 0.814609375\n",
            "Epoch 4 Batch: 2900 TR: 0.3994193947315216 Acc: 0.8198828125\n",
            "Epoch 4 Batch: 3000 TR: 0.4059822973608971 Acc: 0.8125\n",
            "Epoch 4 Batch: 3100 TR: 0.40163654506206514 Acc: 0.8159765625\n",
            "Epoch 4 Batch: 3200 TR: 0.40590925842523573 Acc: 0.8127734375\n",
            "Epoch 4 Batch: 3300 TR: 0.39965870410203935 Acc: 0.81734375\n",
            "Epoch 4 Batch: 3400 TR: 0.4012773105502129 Acc: 0.81671875\n",
            "Epoch 4 Batch: 3500 TR: 0.40407426536083224 Acc: 0.8161328125\n",
            "Epoch 4 Batch: 3600 TR: 0.40101980298757556 Acc: 0.815\n",
            "Epoch 4 Batch: 3700 TR: 0.40725732237100604 Acc: 0.8149609375\n",
            "Epoch 4 Batch: 3800 TR: 0.40232514500617983 Acc: 0.815625\n",
            "Epoch 4 Batch: 3900 TR: 0.4033122956752777 Acc: 0.8182421875\n",
            "Epoch 4 Batch: 4000 TR: 0.40307376176118853 Acc: 0.8168359375\n",
            "Epoch 4 Batch: 4100 TR: 0.40100388050079344 Acc: 0.8187890625\n",
            "Epoch 4 Batch: 4200 TR: 0.39818345665931704 Acc: 0.818828125\n",
            "Epoch 4 Batch: 4300 TR: 0.40442405074834825 Acc: 0.8156640625\n",
            "Epoch 4 Batch: 4400 TR: 0.3979626199603081 Acc: 0.8203125\n",
            "Epoch 4 Batch: 4500 TR: 0.4001456308364868 Acc: 0.819296875\n",
            "Epoch 4 Batch: 4600 TR: 0.39771461725234986 Acc: 0.8198828125\n",
            "Epoch 4 Batch: 4700 TR: 0.39978799074888227 Acc: 0.81921875\n",
            "Epoch 4 Batch: 4800 TR: 0.39678656607866286 Acc: 0.8205078125\n",
            "Epoch 4 Batch: 4900 TR: 0.3996559324860573 Acc: 0.8184765625\n",
            "Epoch 4 Batch: 5000 TR: 0.3958505976200104 Acc: 0.822109375\n",
            "Epoch 4 Batch: 5100 TR: 0.40044768899679184 Acc: 0.8193359375\n",
            "Epoch 4 Batch: 5200 TR: 0.40350668609142304 Acc: 0.817421875\n",
            "Epoch 4 Batch: 5300 TR: 0.4007402229309082 Acc: 0.816171875\n",
            "Epoch 4 Batch: 5400 TR: 0.40258217096328736 Acc: 0.8167578125\n",
            "Epoch 4 Batch: 5500 TR: 0.39518226742744444 Acc: 0.818828125\n",
            "Epoch 4 Batch: 5600 TR: 0.3969791141152382 Acc: 0.8187890625\n",
            "Epoch 4 Batch: 5700 TR: 0.3975726878643036 Acc: 0.82015625\n",
            "Epoch 4 Batch: 5800 TR: 0.404940325319767 Acc: 0.813828125\n",
            "Epoch 4 Batch: 5900 TR: 0.39802913784980776 Acc: 0.816953125\n",
            "Epoch 4 Batch: 6000 TR: 0.4003244000673294 Acc: 0.81765625\n",
            "Epoch 4 Batch: 6100 TR: 0.4042365476489067 Acc: 0.8128125\n",
            "Epoch:  4 loss: 0.40167646379762106\n",
            "Epoch 5 Batch: 100 TR: 0.3973806971311569 Acc: 0.8206640625\n",
            "Epoch 5 Batch: 200 TR: 0.40131586492061616 Acc: 0.8137890625\n",
            "Epoch 5 Batch: 300 TR: 0.4025197565555573 Acc: 0.81546875\n",
            "Epoch 5 Batch: 400 TR: 0.3948831123113632 Acc: 0.8198046875\n",
            "Epoch 5 Batch: 500 TR: 0.38727334290742876 Acc: 0.8243359375\n",
            "Epoch 5 Batch: 600 TR: 0.3950605499744415 Acc: 0.8207421875\n",
            "Epoch 5 Batch: 700 TR: 0.39652701526880263 Acc: 0.820234375\n",
            "Epoch 5 Batch: 800 TR: 0.3960942965745926 Acc: 0.8201953125\n",
            "Epoch 5 Batch: 900 TR: 0.4006850889325142 Acc: 0.8197265625\n",
            "Epoch 5 Batch: 1000 TR: 0.39040510565042497 Acc: 0.822578125\n",
            "Epoch 5 Batch: 1100 TR: 0.39918900161981585 Acc: 0.8176171875\n",
            "Epoch 5 Batch: 1200 TR: 0.39321508079767226 Acc: 0.8208203125\n",
            "Epoch 5 Batch: 1300 TR: 0.3905674952268601 Acc: 0.82359375\n",
            "Epoch 5 Batch: 1400 TR: 0.3974954128265381 Acc: 0.8185546875\n",
            "Epoch 5 Batch: 1500 TR: 0.392880734205246 Acc: 0.8198828125\n",
            "Epoch 5 Batch: 1600 TR: 0.3982055500149727 Acc: 0.81890625\n",
            "Epoch 5 Batch: 1700 TR: 0.3916282904148102 Acc: 0.823046875\n",
            "Epoch 5 Batch: 1800 TR: 0.4027151334285736 Acc: 0.81546875\n",
            "Epoch 5 Batch: 1900 TR: 0.3960143569111824 Acc: 0.821640625\n",
            "Epoch 5 Batch: 2000 TR: 0.3926999795436859 Acc: 0.82140625\n",
            "Epoch 5 Batch: 2100 TR: 0.39281759947538375 Acc: 0.8212109375\n",
            "Epoch 5 Batch: 2200 TR: 0.3935188072919846 Acc: 0.8225390625\n",
            "Epoch 5 Batch: 2300 TR: 0.39566942542791367 Acc: 0.8219140625\n",
            "Epoch 5 Batch: 2400 TR: 0.3900566405057907 Acc: 0.823984375\n",
            "Epoch 5 Batch: 2500 TR: 0.3917258033156395 Acc: 0.823828125\n",
            "Epoch 5 Batch: 2600 TR: 0.38851637274026873 Acc: 0.8232421875\n",
            "Epoch 5 Batch: 2700 TR: 0.38553871780633925 Acc: 0.8250390625\n",
            "Epoch 5 Batch: 2800 TR: 0.3962629812955856 Acc: 0.820078125\n",
            "Epoch 5 Batch: 2900 TR: 0.39115904331207274 Acc: 0.8240625\n",
            "Epoch 5 Batch: 3000 TR: 0.3985196775197983 Acc: 0.8173828125\n",
            "Epoch 5 Batch: 3100 TR: 0.3933876731991768 Acc: 0.8215234375\n",
            "Epoch 5 Batch: 3200 TR: 0.39823791235685346 Acc: 0.8172265625\n",
            "Epoch 5 Batch: 3300 TR: 0.39216694444417954 Acc: 0.8226171875\n",
            "Epoch 5 Batch: 3400 TR: 0.3937815034389496 Acc: 0.822265625\n",
            "Epoch 5 Batch: 3500 TR: 0.39649419754743576 Acc: 0.82078125\n",
            "Epoch 5 Batch: 3600 TR: 0.39277084976434706 Acc: 0.819921875\n",
            "Epoch 5 Batch: 3700 TR: 0.39933119058609007 Acc: 0.8190625\n",
            "Epoch 5 Batch: 3800 TR: 0.39474537640810015 Acc: 0.819921875\n",
            "Epoch 5 Batch: 3900 TR: 0.3956669023633003 Acc: 0.8212109375\n",
            "Epoch 5 Batch: 4000 TR: 0.39569317787885666 Acc: 0.82125\n",
            "Epoch 5 Batch: 4100 TR: 0.3935086479783058 Acc: 0.824375\n",
            "Epoch 5 Batch: 4200 TR: 0.39050627887248995 Acc: 0.8237890625\n",
            "Epoch 5 Batch: 4300 TR: 0.39683533102273943 Acc: 0.8211328125\n",
            "Epoch 5 Batch: 4400 TR: 0.39019918113946916 Acc: 0.8241796875\n",
            "Epoch 5 Batch: 4500 TR: 0.3926939091086388 Acc: 0.8228515625\n",
            "Epoch 5 Batch: 4600 TR: 0.3900406500697136 Acc: 0.823515625\n",
            "Epoch 5 Batch: 4700 TR: 0.3921022418141365 Acc: 0.824140625\n",
            "Epoch 5 Batch: 4800 TR: 0.39001660615205763 Acc: 0.825\n",
            "Epoch 5 Batch: 4900 TR: 0.39247013747692105 Acc: 0.821640625\n",
            "Epoch 5 Batch: 5000 TR: 0.3884941479563713 Acc: 0.8264453125\n",
            "Epoch 5 Batch: 5100 TR: 0.3936703112721443 Acc: 0.8226171875\n",
            "Epoch 5 Batch: 5200 TR: 0.3969158685207367 Acc: 0.819765625\n",
            "Epoch 5 Batch: 5300 TR: 0.39278989285230637 Acc: 0.8209375\n",
            "Epoch 5 Batch: 5400 TR: 0.39497905403375627 Acc: 0.8191796875\n",
            "Epoch 5 Batch: 5500 TR: 0.3875471183657646 Acc: 0.8241015625\n",
            "Epoch 5 Batch: 5600 TR: 0.39016364485025407 Acc: 0.8230859375\n",
            "Epoch 5 Batch: 5700 TR: 0.38997825562953947 Acc: 0.8246875\n",
            "Epoch 5 Batch: 5800 TR: 0.3974234870076179 Acc: 0.8183984375\n",
            "Epoch 5 Batch: 5900 TR: 0.3903066572546959 Acc: 0.821171875\n",
            "Epoch 5 Batch: 6000 TR: 0.39353047013282777 Acc: 0.8223046875\n",
            "Epoch 5 Batch: 6100 TR: 0.3969659695029259 Acc: 0.81609375\n",
            "Epoch:  5 loss: 0.3940012671568737\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jr7bcBTEQMm",
        "outputId": "4d373554-5023-4d2c-b026-ed03bb9c99f2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "path = \"biLSTM.pt\"\r\n",
        "\r\n",
        "torch.save(lstm.state_dict(), \"./models/biLSTM.pt\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "nJmGKmKGEdiX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Evaluating\r\n",
        "\r\n",
        "lstm.eval()\r\n",
        "eval_loss = 0\r\n",
        "acc = 0\r\n",
        "for y_batch, x_batch in islice(loader, trainBatches, trainBatches + testBatches):\r\n",
        "      \r\n",
        "        x_batch = x_batch.to(device)\r\n",
        "        y_batch = y_batch.to(device)\r\n",
        "        output = lstm(x_batch)\r\n",
        "\r\n",
        "        loss = criterion(output, y_batch1)\r\n",
        "\r\n",
        "        for i in range(len(y_batch)):\r\n",
        "          \r\n",
        "          if round(output[i].item()) == (y_batch[i].item()):\r\n",
        "            acc += 1\r\n",
        "\r\n",
        "\r\n",
        "        eval_loss += loss.item()\r\n",
        "        \r\n",
        "eval_loss /= testBatches\r\n",
        "acc /= batch_size*testBatches\r\n",
        "\r\n",
        "print(\"Test loss:\", eval_loss)\r\n",
        "print(\"Test acc:\", acc)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.1944562196731567\n",
            "Test acc: 0.81484375\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOCVyYY6m3uz",
        "outputId": "836b6777-6530-4196-9944-d2862067f37e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}